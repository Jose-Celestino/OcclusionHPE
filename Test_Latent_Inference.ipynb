{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, natsort, glob\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch, datasets\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "import mediapipe as mp\n",
    "import utils\n",
    "import LantentNet\n",
    "cudnn.enabled = True\n",
    "\n",
    "gpu = 0 # GPU ID\n",
    "\n",
    "#Initialize Model\n",
    "model = LantentNet.LantentNet(torchvision.models.resnet.Bottleneck, [3, 4, 6, 3], 66)\n",
    "saved_state_dict = torch.load('models\\Latent_model_0,999.pkl') #For best yaw results\n",
    "model.load_state_dict(saved_state_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Classification and Regression losses\n",
    "criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "reg_criterion = nn.MSELoss().cuda(gpu)\n",
    "\n",
    "\n",
    "MAE = torch.nn.L1Loss(reduction='mean')\n",
    "\n",
    "\n",
    "softmax = nn.Softmax().cuda(gpu)\n",
    "\n",
    "#For classification vector\n",
    "idx_tensor = [idx for idx in range(66)]\n",
    "idx_tensor = Variable(torch.FloatTensor(idx_tensor)).cuda(gpu)\n",
    "\n",
    "\n",
    "model.cuda(gpu)\n",
    "model.eval() #Inference mode\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFERENCE FOR INDIVIDUAL FACE IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input face image \n",
    "img = Image.open('wheel2.jpg')\n",
    "frame = cv2.imread('wheel2.jpg')\n",
    "frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "transformations = transforms.Compose([transforms.Resize(224), transforms.CenterCrop(224), transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "image = transformations(img)\n",
    "\n",
    "\n",
    "image = image.view(1, 3, 224, 224) \n",
    "image = Variable(image).cuda(gpu)\n",
    "x, yaw, pitch, roll = model(image)\n",
    "\n",
    "yaw_predicted = softmax(yaw)#,dim = 1)\n",
    "pitch_predicted = softmax(pitch)#,dim = 1)\n",
    "roll_predicted = softmax(roll)#,dim =1)\n",
    "\n",
    "yaw_predicted = torch.sum(yaw_predicted * idx_tensor, 1) * 3 - 99\n",
    "pitch_predicted = torch.sum(pitch_predicted * idx_tensor, 1) * 3 - 99\n",
    "roll_predicted = torch.sum(roll_predicted * idx_tensor, 1) * 3 - 99\n",
    "\n",
    "yaw_predicted = yaw_predicted.view(1)\n",
    "pitch_predicted = pitch_predicted.view(1)\n",
    "roll_predicted = roll_predicted.view(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "\n",
    "#Visualize result\n",
    "utils.draw_axis(frame, yaw_predicted, pitch_predicted, roll_predicted, tdx = frame.shape[1] / 2, tdy= frame.shape[0] / 2, size = frame.shape[1]/2)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFERENCE FOR INDIVIDUAL IMAGES WITH FACE DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "mpFaceDetection = mp.solutions.face_detection\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "faceDetection = mpFaceDetection.FaceDetection(min_detection_confidence=0.5) #0.65\n",
    "\n",
    "\n",
    "#input face image \n",
    "#img = Image.open('occlusion.jpg')\n",
    "#frame = cv2.imread('occlusion.jpg')\n",
    "img = Image.open('wheel2.jpg')\n",
    "frame = cv2.imread('wheel2.jpg')\n",
    "frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "results = faceDetection.process(frame)\n",
    "\n",
    "detection = results.detections[0]\n",
    "\n",
    "xmin = detection.location_data.relative_bounding_box.xmin\n",
    "xmax = xmin + detection.location_data.relative_bounding_box.width\n",
    "ymin = detection.location_data.relative_bounding_box.ymin\n",
    "ymax = ymin + detection.location_data.relative_bounding_box.height\n",
    "\n",
    "height = frame.shape[0]\n",
    "width = frame.shape[1]\n",
    "\n",
    "bbox_height = ymax-ymin\n",
    "\n",
    "imgRGB = Image.fromarray(frame)\n",
    "\n",
    "xmin_new = xmin*width \n",
    "ymin_new = ymin*height\n",
    "xmax_new = xmax*width\n",
    "ymax_new = ymax*height\n",
    "\n",
    "# widen the face box margin for better pose estimation\n",
    "xmin_new = xmin_new - 10\n",
    "ymin_new = ymin_new - 20 \n",
    "xmax_new = xmax_new + 10\n",
    "ymax_new = ymax_new + 15\n",
    "\n",
    "image = imgRGB.crop((xmin_new, ymin_new ,xmax_new, ymax_new))\n",
    "\n",
    "transformations = transforms.Compose([transforms.Resize(224), transforms.CenterCrop(224), transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "image = transformations(img)\n",
    "\n",
    "\n",
    "image = image.view(1, 3, 224, 224) \n",
    "image = Variable(image).cuda(gpu)\n",
    "x, yaw, pitch, roll = model(image)\n",
    "\n",
    "yaw_predicted = softmax(yaw)#,dim = 1)\n",
    "pitch_predicted = softmax(pitch)#,dim = 1)\n",
    "roll_predicted = softmax(roll)#,dim =1)\n",
    "\n",
    "yaw_predicted = torch.sum(yaw_predicted * idx_tensor, 1) * 3 - 99\n",
    "pitch_predicted = torch.sum(pitch_predicted * idx_tensor, 1) * 3 - 99\n",
    "roll_predicted = torch.sum(roll_predicted * idx_tensor, 1) * 3 - 99\n",
    "\n",
    "yaw_predicted = yaw_predicted.view(1)\n",
    "pitch_predicted = pitch_predicted.view(1)\n",
    "roll_predicted = roll_predicted.view(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "\n",
    "#Visualize result\n",
    "utils.draw_axis(frame, yaw_predicted, pitch_predicted, roll_predicted, tdx = frame.shape[1] / 2, tdy= frame.shape[0] / 2, size = frame.shape[1]/2)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(frame)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "053c6e4ee5ae1f0aeeda0edd312d8b4f74168437095e833c07b841acdd0a11a6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
